{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915a4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "ds = load_dataset(\"lmsys/mt_bench_human_judgments\")\n",
    "human_split = ds[\"human\"]\n",
    "gpt4_split = ds[\"gpt4_pair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979f7967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question_id', 'model_a', 'model_b', 'winner', 'judge', 'conversation_a', 'conversation_b', 'turn']\n"
     ]
    }
   ],
   "source": [
    "print(human_split.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932195fc",
   "metadata": {},
   "source": [
    "## Recreate agreement calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def canonical_judge(judge):\n",
    "    if isinstance(judge, list) and judge and judge[0] == \"gpt-4\":\n",
    "        return \"gpt4-pair\"\n",
    "    if isinstance(judge, str) and judge.startswith((\"expert\", \"author\")):\n",
    "        return \"human\"\n",
    "    return judge\n",
    "\n",
    "def fold_tie(v):\n",
    "    return \"tie\" if \"tie\" in v else v\n",
    "\n",
    "def build_vote_bag(rows):\n",
    "    \"\"\"Build a bag of votes from the rows of the dataset.\"\"\"\n",
    "    bag = [defaultdict(dict), defaultdict(dict)]\n",
    "\n",
    "    for row in rows:\n",
    "        turn = row[\"turn\"] - 1 # change from 1-indexed to 0-indexed\n",
    "\n",
    "        if row[\"model_a\"] < row[\"model_b\"]:\n",
    "            key = (row[\"question_id\"], row[\"model_a\"], row[\"model_b\"])\n",
    "            label = row[\"winner\"]\n",
    "\n",
    "        else:\n",
    "            key = (row[\"question_id\"], row[\"model_b\"], row[\"model_a\"])\n",
    "            label = {\"model_a\" : \"model_b\", \"model_b\" : \"model_a\"}.get(row[\"winner\"], row[\"winner\"])\n",
    "\n",
    "        judge = canonical_judge(row[\"judge\"])\n",
    "\n",
    "        bag[turn].setdefault(key, {}).setdefault(judge, []).append(label)\n",
    "\n",
    "    return bag\n",
    "\n",
    "\n",
    "def agree_turn(bag_turn, judgeA=\"gemini\", judgeB=\"human\", drop_ties=True):\n",
    "    \"\"\"\n",
    "    Return (agree, total) for one turn.\n",
    "    Mirrors MT-Bench reference exactly.\n",
    "    \"\"\"\n",
    "    agree = tot = 0\n",
    "    for votes in bag_turn.values():\n",
    "        if judgeA not in votes or judgeB not in votes:\n",
    "            continue                                # need both judges\n",
    "        vA = fold_tie(votes[judgeA][0])             # LLM gives 1 vote\n",
    "        if drop_ties and vA == \"tie\":\n",
    "            continue\n",
    "        for vB in votes[judgeB]:                    # humans may vote many times\n",
    "            vB = fold_tie(vB)\n",
    "            if drop_ties and vB == \"tie\":\n",
    "                continue\n",
    "            tot   += 1\n",
    "            agree += (vA == vB)                     # bool adds as 1/0\n",
    "    return agree, tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "306a4781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement (Tie: True, turn-1): 1125/1689 = 66.61%\n",
      "Agreement (Tie: False, turn-1): 911/1060 = 85.94%\n",
      "Agreement (Tie: True, turn-2): 1095/1666 = 65.73%\n",
      "Agreement (Tie: False, turn-2): 912/1069 = 85.31%\n"
     ]
    }
   ],
   "source": [
    "bag = build_vote_bag(list(human_split) + list(gpt4_split))\n",
    "\n",
    "for turn in [0, 1]:\n",
    "    for tie in [False, True]:\n",
    "        agree, total = agree_turn(bag[turn], \"gpt4_pair\", \"human\", drop_ties=tie)\n",
    "        print(f\"Agreement (Tie: {not tie}, turn-{turn+1}): {agree}/{total} = {agree/total:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d4cbc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion agreement (turn-1): 85.94% (83.87%, 88.02%)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import bootstrap\n",
    "\n",
    "def prop_agree(bag_turn, jA, jB, n=10_000):\n",
    "    agree, total = agree_turn(bag_turn, jA, jB, drop_ties=True)\n",
    "    hits = np.concatenate([np.ones(agree), np.zeros(total-agree)])  \n",
    "    ci = bootstrap((hits,), lambda x: x.mean(), n_resamples=n, method='basic', confidence_level=0.95).confidence_interval\n",
    "    return hits.mean(), ci.low, ci.high\n",
    "\n",
    "agree, ci_low, ci_high = prop_agree(bag[0], \"gpt4_pair\", \"human\")\n",
    "print(f\"Proportion agreement (turn-1): {agree:.2%} ({ci_low:.2%}, {ci_high:.2%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
